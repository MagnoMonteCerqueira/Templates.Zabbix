<?xml version="1.0" encoding="UTF-8"?>
<zabbix_export><version>6.0</version><date>2023-02-11T16:14:48Z</date><groups><group><uuid>a571c0d144b14fd4a87a9d9b2aa9fcd6</uuid><name>Templates/Applications</name></group></groups><templates><template><uuid>09fb25d089f7467f860895f6e71d3fa2</uuid><template>Ceph by Zabbix agent 2</template><name>Ceph by Zabbix agent 2</name><description>You can discuss this template or leave feedback on our forum https://www.zabbix.com/forum/zabbix-suggestions-and-feedback/410059-discussion-thread-for-official-zabbix-template-ceph

Template tooling version used: 0.41</description><groups><group><name>Templates/Applications</name></group></groups><items><item><uuid>af3e6faf835f41ef93cbbc44aa57f97e</uuid><name>Ceph: Get df</name><key>ceph.df.details[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key><history>0</history><trends>0</trends><value_type>TEXT</value_type><tags><tag><tag>component</tag><value>disk</value></tag><tag><tag>component</tag><value>raw</value></tag></tags></item><item><uuid>45c9df734d424e6a8d3fea99c4a66246</uuid><name>Ceph: Minimum Mon release version</name><type>DEPENDENT</type><key>ceph.min_mon_release_name</key><delay>0</delay><history>7d</history><trends>0</trends><value_type>CHAR</value_type><description>min_mon_release_name</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.min_mon_release_name</parameter></parameters></step><step><type>DISCARD_UNCHANGED_HEARTBEAT</type><parameters><parameter>1h</parameter></parameters></step></preprocessing><master_item><key>ceph.status[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>monitors</value></tag></tags><triggers><trigger><uuid>716f166b3943443aba70a4faed882ffb</uuid><expression>last(/Ceph by Zabbix agent 2/ceph.min_mon_release_name,#1)&lt;&gt;last(/Ceph by Zabbix agent 2/ceph.min_mon_release_name,#2) and length(last(/Ceph by Zabbix agent 2/ceph.min_mon_release_name))&gt;0</expression><name>Ceph: Minimum monitor release version has changed</name><event_name>Ceph: Minimum monitor release version has changed (new version: {ITEM.VALUE})</event_name><priority>INFO</priority><description>A Ceph version has changed. Perform Ack to close manually.</description><manual_close>YES</manual_close><tags><tag><tag>scope</tag><value>notice</value></tag></tags></trigger></triggers></item><item><uuid>5d5276504d6c41eebe8e18846edcff45</uuid><name>Ceph: Number of Monitors</name><type>DEPENDENT</type><key>ceph.num_mon</key><delay>0</delay><history>7d</history><description>The number of Monitors configured in a Ceph cluster.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.num_mon</parameter></parameters></step><step><type>DISCARD_UNCHANGED_HEARTBEAT</type><parameters><parameter>30m</parameter></parameters></step></preprocessing><master_item><key>ceph.status[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>monitors</value></tag></tags></item><item><uuid>09d7a872f35349c6ba7d4a678bf71652</uuid><name>Ceph: Number of OSDs</name><type>DEPENDENT</type><key>ceph.num_osd</key><delay>0</delay><history>7d</history><description>The number of the known storage daemons in a Ceph cluster.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.num_osd</parameter></parameters></step><step><type>DISCARD_UNCHANGED_HEARTBEAT</type><parameters><parameter>10m</parameter></parameters></step></preprocessing><master_item><key>ceph.status[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag><tag><tag>component</tag><value>osd</value></tag></tags></item><item><uuid>795939e16e70475381e917b213bf6f70</uuid><name>Ceph: Number of OSDs in state: IN</name><type>DEPENDENT</type><key>ceph.num_osd_in</key><delay>0</delay><history>7d</history><description>The total number of the participating storage daemons in a Ceph cluster.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.num_osd_in</parameter></parameters></step><step><type>DISCARD_UNCHANGED_HEARTBEAT</type><parameters><parameter>10m</parameter></parameters></step></preprocessing><master_item><key>ceph.status[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag><tag><tag>component</tag><value>osd</value></tag></tags></item><item><uuid>d2d5caaad2914fb1ba07343956edb5b8</uuid><name>Ceph: Number of OSDs in state: UP</name><type>DEPENDENT</type><key>ceph.num_osd_up</key><delay>0</delay><history>7d</history><description>The total number of the online storage daemons in a Ceph cluster.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.num_osd_up</parameter></parameters></step><step><type>DISCARD_UNCHANGED_HEARTBEAT</type><parameters><parameter>10m</parameter></parameters></step></preprocessing><master_item><key>ceph.status[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag><tag><tag>component</tag><value>osd</value></tag></tags></item><item><uuid>46ea920b0951408daa5d678f298b1097</uuid><name>Ceph: Number of Placement Groups</name><type>DEPENDENT</type><key>ceph.num_pg</key><delay>0</delay><history>7d</history><description>The total number of Placement Groups in a Ceph cluster.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.num_pg</parameter></parameters></step><step><type>DISCARD_UNCHANGED_HEARTBEAT</type><parameters><parameter>10m</parameter></parameters></step></preprocessing><master_item><key>ceph.status[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag><tag><tag>component</tag><value>placement-groups</value></tag></tags></item><item><uuid>97fbecc8ee824e658dd95d8115fec5e9</uuid><name>Ceph: Number of Placement Groups in Temporary state</name><type>DEPENDENT</type><key>ceph.num_pg_temp</key><delay>0</delay><history>7d</history><description>The total number of Placement Groups in a *pg_temp* state</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.num_pg_temp</parameter></parameters></step></preprocessing><master_item><key>ceph.osd.dump[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>placement-groups</value></tag></tags></item><item><uuid>b0e36ff76db049ab870fa26c29e5e69c</uuid><name>Ceph: Number of Pools</name><type>DEPENDENT</type><key>ceph.num_pools</key><delay>0</delay><history>7d</history><description>The total number of pools in a Ceph cluster.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.num_pools</parameter></parameters></step></preprocessing><master_item><key>ceph.df.details[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag><tag><tag>component</tag><value>pools</value></tag></tags></item><item><uuid>e7eb1f67d81c4e2ba7c57cfbc81d1a00</uuid><name>Ceph: Get OSD dump</name><key>ceph.osd.dump[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key><history>0</history><trends>0</trends><value_type>TEXT</value_type><tags><tag><tag>component</tag><value>osd</value></tag><tag><tag>component</tag><value>raw</value></tag></tags></item><item><uuid>35b63ca6519e4137bb7655e37ed08e51</uuid><name>Ceph: Get OSD stats</name><key>ceph.osd.stats[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key><history>0</history><trends>0</trends><value_type>TEXT</value_type><tags><tag><tag>component</tag><value>osd</value></tag><tag><tag>component</tag><value>raw</value></tag></tags></item><item><uuid>0d6cffa1f06748738431524667ea8db0</uuid><name>Ceph: Ceph backfill full ratio</name><type>DEPENDENT</type><key>ceph.osd_backfillfull_ratio</key><delay>0</delay><history>7d</history><value_type>FLOAT</value_type><description>The backfill full ratio setting of the Ceph cluster as configured on OSDMap.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.osd_backfillfull_ratio</parameter></parameters></step><step><type>DISCARD_UNCHANGED_HEARTBEAT</type><parameters><parameter>10m</parameter></parameters></step></preprocessing><master_item><key>ceph.osd.dump[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag></tags></item><item><uuid>52c5efe132b8404f8fc4ac995c3d5c2c</uuid><name>Ceph: Ceph OSD avg fill</name><type>DEPENDENT</type><key>ceph.osd_fill.avg</key><delay>0</delay><history>7d</history><value_type>FLOAT</value_type><units>%</units><description>The average fill of OSDs.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.osd_fill.avg</parameter></parameters></step></preprocessing><master_item><key>ceph.osd.stats[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag><tag><tag>component</tag><value>osd</value></tag></tags></item><item><uuid>453cebeed3214153ba4e3a5b224c063d</uuid><name>Ceph: Ceph OSD max fill</name><type>DEPENDENT</type><key>ceph.osd_fill.max</key><delay>0</delay><history>7d</history><value_type>FLOAT</value_type><units>%</units><description>The percentage of the most filled OSD.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.osd_fill.max</parameter></parameters></step></preprocessing><master_item><key>ceph.osd.stats[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag><tag><tag>component</tag><value>osd</value></tag></tags></item><item><uuid>f6efbd37e8104272be131d686a700808</uuid><name>Ceph: Ceph OSD min fill</name><type>DEPENDENT</type><key>ceph.osd_fill.min</key><delay>0</delay><history>7d</history><value_type>FLOAT</value_type><units>%</units><description>The percentage fill of the minimum filled OSD.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.osd_fill.min</parameter></parameters></step></preprocessing><master_item><key>ceph.osd.stats[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag><tag><tag>component</tag><value>osd</value></tag></tags></item><item><uuid>532891a1d8934211a016524b136cfb1e</uuid><name>Ceph: Ceph full ratio</name><type>DEPENDENT</type><key>ceph.osd_full_ratio</key><delay>0</delay><history>7d</history><value_type>FLOAT</value_type><description>The full ratio setting of the Ceph cluster as configured on OSDMap.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.osd_full_ratio</parameter></parameters></step><step><type>DISCARD_UNCHANGED_HEARTBEAT</type><parameters><parameter>10m</parameter></parameters></step></preprocessing><master_item><key>ceph.osd.dump[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag></tags></item><item><uuid>074c0881384446ea90e99d355afe4f4f</uuid><name>Ceph: Ceph OSD Apply latency Avg</name><type>DEPENDENT</type><key>ceph.osd_latency_apply.avg</key><delay>0</delay><history>7d</history><value_type>FLOAT</value_type><units>ms</units><description>The average apply latency of OSDs.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.osd_latency_apply.avg</parameter></parameters></step></preprocessing><master_item><key>ceph.osd.stats[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag><tag><tag>component</tag><value>osd</value></tag></tags></item><item><uuid>ef0a76f0c16147d1a280e00e66d3806f</uuid><name>Ceph: Ceph OSD Apply latency Max</name><type>DEPENDENT</type><key>ceph.osd_latency_apply.max</key><delay>0</delay><history>7d</history><value_type>FLOAT</value_type><units>ms</units><description>The maximum apply latency of OSDs.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.osd_latency_apply.max</parameter></parameters></step></preprocessing><master_item><key>ceph.osd.stats[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag><tag><tag>component</tag><value>osd</value></tag></tags></item><item><uuid>d45ad876b0a04345be347af54211aa69</uuid><name>Ceph: Ceph OSD Apply latency Min</name><type>DEPENDENT</type><key>ceph.osd_latency_apply.min</key><delay>0</delay><history>7d</history><value_type>FLOAT</value_type><units>ms</units><description>The minimum apply latency of OSDs.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.osd_latency_apply.min</parameter></parameters></step></preprocessing><master_item><key>ceph.osd.stats[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag><tag><tag>component</tag><value>osd</value></tag></tags></item><item><uuid>52e1b146c36e4c2e82acf36f1c7d12eb</uuid><name>Ceph: Ceph OSD Commit latency Avg</name><type>DEPENDENT</type><key>ceph.osd_latency_commit.avg</key><delay>0</delay><history>7d</history><value_type>FLOAT</value_type><units>ms</units><description>The average commit latency of OSDs.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.osd_latency_commit.avg</parameter></parameters></step></preprocessing><master_item><key>ceph.osd.stats[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag><tag><tag>component</tag><value>osd</value></tag></tags></item><item><uuid>3027a1dbdd8e4f9bbef8927b92eb8e77</uuid><name>Ceph: Ceph OSD Commit latency Max</name><type>DEPENDENT</type><key>ceph.osd_latency_commit.max</key><delay>0</delay><history>7d</history><value_type>FLOAT</value_type><units>ms</units><description>The maximum commit latency of OSDs.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.osd_latency_commit.max</parameter></parameters></step></preprocessing><master_item><key>ceph.osd.stats[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag><tag><tag>component</tag><value>osd</value></tag></tags></item><item><uuid>b9900b84c22843dab4ad335b9642e040</uuid><name>Ceph: Ceph OSD Commit latency Min</name><type>DEPENDENT</type><key>ceph.osd_latency_commit.min</key><delay>0</delay><history>7d</history><value_type>FLOAT</value_type><units>ms</units><description>The minimum commit latency of OSDs.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.osd_latency_commit.min</parameter></parameters></step></preprocessing><master_item><key>ceph.osd.stats[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag><tag><tag>component</tag><value>osd</value></tag></tags></item><item><uuid>477d94bd838d4273a556537de36bb1f6</uuid><name>Ceph: Ceph nearfull ratio</name><type>DEPENDENT</type><key>ceph.osd_nearfull_ratio</key><delay>0</delay><history>7d</history><value_type>FLOAT</value_type><description>The near full ratio setting of the Ceph cluster as configured on OSDMap.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.osd_nearfull_ratio</parameter></parameters></step><step><type>DISCARD_UNCHANGED_HEARTBEAT</type><parameters><parameter>10m</parameter></parameters></step></preprocessing><master_item><key>ceph.osd.dump[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag></tags></item><item><uuid>27ea5688271347bca429d91ace62d4e2</uuid><name>Ceph: Ceph OSD avg PGs</name><type>DEPENDENT</type><key>ceph.osd_pgs.avg</key><delay>0</delay><history>7d</history><value_type>FLOAT</value_type><description>The average amount of Placement Groups on OSDs.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.osd_pgs.avg</parameter></parameters></step></preprocessing><master_item><key>ceph.osd.stats[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag><tag><tag>component</tag><value>osd</value></tag><tag><tag>component</tag><value>placement-groups</value></tag></tags></item><item><uuid>4174d7d3190e47ccb55b1e50da4cedc5</uuid><name>Ceph: Ceph OSD max PGs</name><type>DEPENDENT</type><key>ceph.osd_pgs.max</key><delay>0</delay><history>7d</history><value_type>FLOAT</value_type><description>The maximum amount of Placement Groups on OSDs.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.osd_pgs.max</parameter></parameters></step></preprocessing><master_item><key>ceph.osd.stats[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag><tag><tag>component</tag><value>osd</value></tag><tag><tag>component</tag><value>placement-groups</value></tag></tags></item><item><uuid>47f56243cd1c430fae217d1a0cbc4a99</uuid><name>Ceph: Ceph OSD min PGs</name><type>DEPENDENT</type><key>ceph.osd_pgs.min</key><delay>0</delay><history>7d</history><value_type>FLOAT</value_type><description>The minimum amount of Placement Groups on OSDs.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.osd_pgs.min</parameter></parameters></step></preprocessing><master_item><key>ceph.osd.stats[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag><tag><tag>component</tag><value>osd</value></tag><tag><tag>component</tag><value>placement-groups</value></tag></tags></item><item><uuid>4023ca309692470eab2651f69d49419a</uuid><name>Ceph: Overall cluster status</name><type>DEPENDENT</type><key>ceph.overall_status</key><delay>0</delay><history>7d</history><description>The overall Ceph cluster status, eg 0 - HEALTH_OK, 1 - HEALTH_WARN or 2 - HEALTH_ERR.</description><valuemap><name>Ceph cluster status</name></valuemap><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.overall_status</parameter></parameters></step><step><type>DISCARD_UNCHANGED_HEARTBEAT</type><parameters><parameter>10m</parameter></parameters></step></preprocessing><master_item><key>ceph.status[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>health</value></tag></tags><triggers><trigger><uuid>6ab06350bd8b426681f1b8bddde76a13</uuid><expression>last(/Ceph by Zabbix agent 2/ceph.overall_status)=2</expression><name>Ceph: Cluster in ERROR state</name><priority>AVERAGE</priority><manual_close>YES</manual_close><tags><tag><tag>scope</tag><value>availability</value></tag></tags></trigger><trigger><uuid>8b6ba1a7ae014e80a5287ffd13b5d8aa</uuid><expression>last(/Ceph by Zabbix agent 2/ceph.overall_status)=1</expression><recovery_mode>RECOVERY_EXPRESSION</recovery_mode><recovery_expression>last(/Ceph by Zabbix agent 2/ceph.overall_status)=0</recovery_expression><name>Ceph: Cluster in WARNING state</name><priority>WARNING</priority><manual_close>YES</manual_close><dependencies><dependency><name>Ceph: Cluster in ERROR state</name><expression>last(/Ceph by Zabbix agent 2/ceph.overall_status)=2</expression></dependency></dependencies><tags><tag><tag>scope</tag><value>availability</value></tag></tags></trigger></triggers></item><item><uuid>9b073153d7474b0abfccb1844d0e6981</uuid><name>Ceph: Number of Placement Groups in Active state</name><type>DEPENDENT</type><key>ceph.pg_states.active</key><delay>0</delay><history>7d</history><description>The total number of Placement Groups in an active state.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.pg_states.active</parameter></parameters></step></preprocessing><master_item><key>ceph.status[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>placement-groups</value></tag></tags></item><item><uuid>1471a13aaadc48c7a265835abcb93a03</uuid><name>Ceph: Number of Placement Groups in Backfilling state</name><type>DEPENDENT</type><key>ceph.pg_states.backfilling</key><delay>0</delay><history>7d</history><description>The total number of Placement Groups in a backfill state.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.pg_states.backfilling</parameter></parameters></step></preprocessing><master_item><key>ceph.status[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>placement-groups</value></tag></tags></item><item><uuid>3b44c79e03d4402ba442331593dbdfa3</uuid><name>Ceph: Number of Placement Groups in backfill_toofull state</name><type>DEPENDENT</type><key>ceph.pg_states.backfill_toofull</key><delay>0</delay><history>7d</history><description>The total number of Placement Groups in a *backfill_toofull state*.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.pg_states.backfill_toofull</parameter></parameters></step></preprocessing><master_item><key>ceph.status[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>placement-groups</value></tag></tags></item><item><uuid>ada3f638ee2e48eeb8889526898aed2f</uuid><name>Ceph: Number of Placement Groups in backfill_wait state</name><type>DEPENDENT</type><key>ceph.pg_states.backfill_wait</key><delay>0</delay><history>7d</history><description>The total number of Placement Groups in a *backfill_wait* state.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.pg_states.backfill_wait</parameter></parameters></step></preprocessing><master_item><key>ceph.status[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>placement-groups</value></tag></tags></item><item><uuid>b1af2b88fe424723b97c9aa4eee12d83</uuid><name>Ceph: Number of Placement Groups in Clean state</name><type>DEPENDENT</type><key>ceph.pg_states.clean</key><delay>0</delay><history>7d</history><description>The total number of Placement Groups in a clean state.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.pg_states.clean</parameter></parameters></step></preprocessing><master_item><key>ceph.status[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>placement-groups</value></tag></tags></item><item><uuid>f8acf8f66fbc401799d3515eb3e2ea43</uuid><name>Ceph: Number of Placement Groups in degraded state</name><type>DEPENDENT</type><key>ceph.pg_states.degraded</key><delay>0</delay><history>7d</history><description>The total number of Placement Groups in a degraded state.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.pg_states.degraded</parameter></parameters></step></preprocessing><master_item><key>ceph.status[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>placement-groups</value></tag></tags></item><item><uuid>79e056b9e3af40eabab0f927fb326491</uuid><name>Ceph: Number of Placement Groups in inconsistent state</name><type>DEPENDENT</type><key>ceph.pg_states.inconsistent</key><delay>0</delay><history>7d</history><description>The total number of Placement Groups in an inconsistent state.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.pg_states.inconsistent</parameter></parameters></step></preprocessing><master_item><key>ceph.status[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>placement-groups</value></tag></tags></item><item><uuid>9ddef3d2e7df43eda7d2835ceac19d32</uuid><name>Ceph: Number of Placement Groups in Peering state</name><type>DEPENDENT</type><key>ceph.pg_states.peering</key><delay>0</delay><history>7d</history><description>The total number of Placement Groups in a peering state.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.pg_states.peering</parameter></parameters></step></preprocessing><master_item><key>ceph.status[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>placement-groups</value></tag></tags></item><item><uuid>573461fc94e84f96b8ae6f6d89916424</uuid><name>Ceph: Number of Placement Groups in recovering state</name><type>DEPENDENT</type><key>ceph.pg_states.recovering</key><delay>0</delay><history>7d</history><description>The total number of Placement Groups in a recovering state.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.pg_states.recovering</parameter></parameters></step></preprocessing><master_item><key>ceph.status[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>placement-groups</value></tag></tags></item><item><uuid>c150a9414fee40acaa65d532fd110c4e</uuid><name>Ceph: Number of Placement Groups in recovery_wait state</name><type>DEPENDENT</type><key>ceph.pg_states.recovery_wait</key><delay>0</delay><history>7d</history><description>The total number of Placement Groups in a *recovery_wait* state.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.pg_states.recovery_wait</parameter></parameters></step></preprocessing><master_item><key>ceph.status[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>placement-groups</value></tag></tags></item><item><uuid>bac3270faf854267a466eaa6a4acad91</uuid><name>Ceph: Number of Placement Groups in remapped state</name><type>DEPENDENT</type><key>ceph.pg_states.remapped</key><delay>0</delay><history>7d</history><description>The total number of Placement Groups in a remapped state.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.pg_states.remapped</parameter></parameters></step></preprocessing><master_item><key>ceph.status[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>placement-groups</value></tag></tags></item><item><uuid>8a0117845436492d951e96b46eb67e1c</uuid><name>Ceph: Number of Placement Groups in Scrubbing state</name><type>DEPENDENT</type><key>ceph.pg_states.scrubbing</key><delay>0</delay><history>7d</history><description>The total number of Placement Groups in a scrubbing state.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.pg_states.scrubbing</parameter></parameters></step></preprocessing><master_item><key>ceph.status[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>placement-groups</value></tag></tags></item><item><uuid>4998e4542ed746f08f82ecf53b553c36</uuid><name>Ceph: Number of Placement Groups in Undersized state</name><type>DEPENDENT</type><key>ceph.pg_states.undersized</key><delay>0</delay><history>7d</history><description>The total number of Placement Groups in an undersized state.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.pg_states.undersized</parameter></parameters></step></preprocessing><master_item><key>ceph.status[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>placement-groups</value></tag></tags></item><item><uuid>c922613c5ffb4f689c01f13143633ec3</uuid><name>Ceph: Number of Placement Groups in Unknown state</name><type>DEPENDENT</type><key>ceph.pg_states.unknown</key><delay>0</delay><history>7d</history><description>The total number of Placement Groups in an unknown state.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.pg_states.unknown</parameter></parameters></step></preprocessing><master_item><key>ceph.status[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>placement-groups</value></tag></tags></item><item><uuid>911e8a654ca44e7ca56b8010ac7381c8</uuid><name>Ceph: Ping</name><key>ceph.ping[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key><history>7d</history><valuemap><name>Service state</name></valuemap><preprocessing><step><type>DISCARD_UNCHANGED_HEARTBEAT</type><parameters><parameter>30m</parameter></parameters></step></preprocessing><tags><tag><tag>component</tag><value>application</value></tag><tag><tag>component</tag><value>health</value></tag></tags><triggers><trigger><uuid>9ffc9a5c3d1c47d288c665c8be7d2fbb</uuid><expression>last(/Ceph by Zabbix agent 2/ceph.ping[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;])=0</expression><name>Ceph: Can not connect to cluster</name><priority>AVERAGE</priority><description>The connection to the Ceph RESTful module is broken (if there is any error presented including *AUTH* and the configuration issues).</description><tags><tag><tag>scope</tag><value>availability</value></tag></tags></trigger></triggers></item><item><uuid>89d7df2ebfbc4aa88b4ff4de44dc4b8b</uuid><name>Ceph: Ceph Read bandwidth</name><type>DEPENDENT</type><key>ceph.rd_bytes.rate</key><delay>0</delay><history>7d</history><value_type>FLOAT</value_type><units>Bps</units><description>The global read bytes per second.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.rd_bytes</parameter></parameters></step><step><type>CHANGE_PER_SECOND</type><parameters><parameter/></parameters></step></preprocessing><master_item><key>ceph.df.details[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag><tag><tag>component</tag><value>disk</value></tag></tags></item><item><uuid>8a35a37de63746498291993d4f3fc1cc</uuid><name>Ceph: Ceph Read operations per sec</name><type>DEPENDENT</type><key>ceph.rd_ops.rate</key><delay>0</delay><history>7d</history><value_type>FLOAT</value_type><units>ops</units><description>The global read operations per second.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.rd_ops</parameter></parameters></step><step><type>CHANGE_PER_SECOND</type><parameters><parameter/></parameters></step></preprocessing><master_item><key>ceph.df.details[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag><tag><tag>component</tag><value>disk</value></tag></tags></item><item><uuid>8b43d105f9d64a3a94196f3f3bc7eac3</uuid><name>Ceph: Get overall cluster status</name><key>ceph.status[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key><history>0</history><trends>0</trends><value_type>TEXT</value_type><tags><tag><tag>component</tag><value>raw</value></tag></tags></item><item><uuid>5e400c932acf4ad498e17daca0ad4943</uuid><name>Ceph: Total bytes available</name><type>DEPENDENT</type><key>ceph.total_avail_bytes</key><delay>0</delay><history>7d</history><units>B</units><description>The total bytes available in a Ceph cluster.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.total_avail_bytes</parameter></parameters></step></preprocessing><master_item><key>ceph.df.details[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag><tag><tag>component</tag><value>disk</value></tag></tags></item><item><uuid>c4b1a31efb5f47518cc5dd6082f3a42b</uuid><name>Ceph: Total bytes</name><type>DEPENDENT</type><key>ceph.total_bytes</key><delay>0</delay><history>7d</history><units>B</units><description>The total (RAW) capacity of a Ceph cluster in bytes.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.total_bytes</parameter></parameters></step></preprocessing><master_item><key>ceph.df.details[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag><tag><tag>component</tag><value>disk</value></tag></tags></item><item><uuid>d3910275462b43dba1fa8022a398ed1c</uuid><name>Ceph: Total number of objects</name><type>DEPENDENT</type><key>ceph.total_objects</key><delay>0</delay><history>7d</history><description>The total number of objects in a Ceph cluster.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.total_objects</parameter></parameters></step></preprocessing><master_item><key>ceph.df.details[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag></tags></item><item><uuid>6ad8e289eef349ab8ebfd4cc92a35c18</uuid><name>Ceph: Total bytes used</name><type>DEPENDENT</type><key>ceph.total_used_bytes</key><delay>0</delay><history>7d</history><units>B</units><description>The total bytes used in a Ceph cluster.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.total_used_bytes</parameter></parameters></step></preprocessing><master_item><key>ceph.df.details[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag><tag><tag>component</tag><value>disk</value></tag></tags></item><item><uuid>51e100668e5344d29afd50dc9b9eabc9</uuid><name>Ceph: Ceph Write bandwidth</name><type>DEPENDENT</type><key>ceph.wr_bytes.rate</key><delay>0</delay><history>7d</history><value_type>FLOAT</value_type><units>Bps</units><description>Global write Bytes per second</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.wr_bytes</parameter></parameters></step><step><type>CHANGE_PER_SECOND</type><parameters><parameter/></parameters></step></preprocessing><master_item><key>ceph.df.details[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag><tag><tag>component</tag><value>disk</value></tag></tags></item><item><uuid>0a7203defa7147f7b975b404e6706b60</uuid><name>Ceph: Ceph Write operations per sec</name><type>DEPENDENT</type><key>ceph.wr_ops.rate</key><delay>0</delay><history>7d</history><value_type>FLOAT</value_type><units>ops</units><description>The global write operations per second.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.wr_ops</parameter></parameters></step><step><type>CHANGE_PER_SECOND</type><parameters><parameter/></parameters></step></preprocessing><master_item><key>ceph.df.details[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>cluster</value></tag><tag><tag>component</tag><value>disk</value></tag></tags></item></items><discovery_rules><discovery_rule><uuid>374557a43a824d938e9a8e656151e0c9</uuid><name>OSD</name><key>ceph.osd.discovery[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key><delay>1h</delay><item_prototypes><item_prototype><uuid>4f7a72a5c4c14b9da63ddbae9e2ebf5f</uuid><name>Ceph: [osd.{#OSDNAME}] OSD fill</name><type>DEPENDENT</type><key>ceph.osd[{#OSDNAME},fill]</key><delay>0</delay><history>7d</history><value_type>FLOAT</value_type><units>%</units><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.osds.{#OSDNAME}.osd_fill</parameter></parameters><error_handler>DISCARD_VALUE</error_handler></step></preprocessing><master_item><key>ceph.osd.stats[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>class</tag><value>{#CLASS}</value></tag><tag><tag>component</tag><value>osd</value></tag><tag><tag>host</tag><value>{#HOST}</value></tag><tag><tag>osd</tag><value>{#OSDNAME}</value></tag></tags></item_prototype><item_prototype><uuid>fc2518ca8b9341d8befc6f9b1cbd4b79</uuid><name>Ceph: [osd.{#OSDNAME}] OSD in</name><type>DEPENDENT</type><key>ceph.osd[{#OSDNAME},in]</key><delay>0</delay><history>7d</history><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.osds.{#OSDNAME}.in</parameter></parameters></step><step><type>DISCARD_UNCHANGED_HEARTBEAT</type><parameters><parameter>10m</parameter></parameters></step></preprocessing><master_item><key>ceph.osd.dump[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>class</tag><value>{#CLASS}</value></tag><tag><tag>component</tag><value>osd</value></tag><tag><tag>host</tag><value>{#HOST}</value></tag><tag><tag>osd</tag><value>{#OSDNAME}</value></tag></tags></item_prototype><item_prototype><uuid>2eb6a0d999d14906a4737ed32834ccc7</uuid><name>Ceph: [osd.{#OSDNAME}] OSD latency apply</name><type>DEPENDENT</type><key>ceph.osd[{#OSDNAME},latency_apply]</key><delay>0</delay><history>7d</history><value_type>FLOAT</value_type><units>ms</units><description>The time taken to flush an update to disks.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.osds.{#OSDNAME}.osd_latency_apply</parameter></parameters><error_handler>DISCARD_VALUE</error_handler></step></preprocessing><master_item><key>ceph.osd.stats[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>class</tag><value>{#CLASS}</value></tag><tag><tag>component</tag><value>osd</value></tag><tag><tag>host</tag><value>{#HOST}</value></tag><tag><tag>osd</tag><value>{#OSDNAME}</value></tag></tags></item_prototype><item_prototype><uuid>14f392b369504f10b7e068522ac4a086</uuid><name>Ceph: [osd.{#OSDNAME}] OSD latency commit</name><type>DEPENDENT</type><key>ceph.osd[{#OSDNAME},latency_commit]</key><delay>0</delay><history>7d</history><value_type>FLOAT</value_type><units>ms</units><description>The time taken to commit an operation to the journal.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.osds.{#OSDNAME}.osd_latency_commit</parameter></parameters><error_handler>DISCARD_VALUE</error_handler></step></preprocessing><master_item><key>ceph.osd.stats[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>class</tag><value>{#CLASS}</value></tag><tag><tag>component</tag><value>osd</value></tag><tag><tag>host</tag><value>{#HOST}</value></tag><tag><tag>osd</tag><value>{#OSDNAME}</value></tag></tags></item_prototype><item_prototype><uuid>63234342c0bd49e6b1f8737bf595851f</uuid><name>Ceph: [osd.{#OSDNAME}] OSD PGs</name><type>DEPENDENT</type><key>ceph.osd[{#OSDNAME},num_pgs]</key><delay>0</delay><history>7d</history><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.osds.{#OSDNAME}.num_pgs</parameter></parameters><error_handler>DISCARD_VALUE</error_handler></step></preprocessing><master_item><key>ceph.osd.stats[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>class</tag><value>{#CLASS}</value></tag><tag><tag>component</tag><value>osd</value></tag><tag><tag>host</tag><value>{#HOST}</value></tag><tag><tag>osd</tag><value>{#OSDNAME}</value></tag></tags></item_prototype><item_prototype><uuid>12c20b2fbf10466bba7e1097c014e968</uuid><name>Ceph: [osd.{#OSDNAME}] OSD up</name><type>DEPENDENT</type><key>ceph.osd[{#OSDNAME},up]</key><delay>0</delay><history>7d</history><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.osds.{#OSDNAME}.up</parameter></parameters></step><step><type>DISCARD_UNCHANGED_HEARTBEAT</type><parameters><parameter>10m</parameter></parameters></step></preprocessing><master_item><key>ceph.osd.dump[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>class</tag><value>{#CLASS}</value></tag><tag><tag>component</tag><value>osd</value></tag><tag><tag>host</tag><value>{#HOST}</value></tag><tag><tag>osd</tag><value>{#OSDNAME}</value></tag></tags><trigger_prototypes><trigger_prototype><uuid>21535bb935b44b3aa073542db3cc7827</uuid><expression>last(/Ceph by Zabbix agent 2/ceph.osd[{#OSDNAME},up]) = 0</expression><name>Ceph: OSD osd.{#OSDNAME} is down</name><priority>AVERAGE</priority><description>OSD osd.{#OSDNAME} is marked &quot;down&quot; in the *osdmap*.
The OSD daemon may have been stopped, or peer OSDs may be unable to reach the OSD over the network.</description><tags><tag><tag>scope</tag><value>availability</value></tag></tags></trigger_prototype></trigger_prototypes></item_prototype></item_prototypes><trigger_prototypes><trigger_prototype><uuid>cd04e8d542a04bdf89abad7ee4719e75</uuid><expression>min(/Ceph by Zabbix agent 2/ceph.osd[{#OSDNAME},fill],15m) &gt; last(/Ceph by Zabbix agent 2/ceph.osd_nearfull_ratio)*100</expression><name>Ceph: Ceph OSD osd.{#OSDNAME} is near full</name><priority>WARNING</priority><dependencies><dependency><name>Ceph: OSD osd.{#OSDNAME} is full</name><expression>min(/Ceph by Zabbix agent 2/ceph.osd[{#OSDNAME},fill],15m) &gt; last(/Ceph by Zabbix agent 2/ceph.osd_full_ratio)*100</expression></dependency></dependencies><tags><tag><tag>scope</tag><value>capacity</value></tag></tags></trigger_prototype><trigger_prototype><uuid>5d7a028166584c29b959914ce904a713</uuid><expression>min(/Ceph by Zabbix agent 2/ceph.osd[{#OSDNAME},fill],15m) &gt; last(/Ceph by Zabbix agent 2/ceph.osd_full_ratio)*100</expression><name>Ceph: OSD osd.{#OSDNAME} is full</name><priority>AVERAGE</priority><tags><tag><tag>scope</tag><value>capacity</value></tag></tags></trigger_prototype></trigger_prototypes><graph_prototypes><graph_prototype><uuid>c88d53bfa7b8456aa70b4d7a2cb63ef5</uuid><name>Ceph: [osd.{#OSDNAME}] OSD latency</name><graph_items><graph_item><color>1A7C11</color><item><host>Ceph by Zabbix agent 2</host><key>ceph.osd[{#OSDNAME},latency_apply]</key></item></graph_item><graph_item><sortorder>1</sortorder><color>2774A4</color><item><host>Ceph by Zabbix agent 2</host><key>ceph.osd[{#OSDNAME},latency_commit]</key></item></graph_item></graph_items></graph_prototype></graph_prototypes></discovery_rule><discovery_rule><uuid>fb6b4d27f46e4160ad978244aa845d0e</uuid><name>Pool</name><key>ceph.pool.discovery[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key><delay>1h</delay><item_prototypes><item_prototype><uuid>1090dc09ce79458e9471863fcb973460</uuid><name>Ceph: [{#POOLNAME}] Pool Used</name><type>DEPENDENT</type><key>ceph.pool[&quot;{#POOLNAME}&quot;,bytes_used]</key><delay>0</delay><history>7d</history><units>B</units><description>The total bytes used in a pool.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.pools[&quot;{#POOLNAME}&quot;].bytes_used</parameter></parameters></step></preprocessing><master_item><key>ceph.df.details[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>pools</value></tag><tag><tag>crushrule</tag><value>{#CRUSHRULE}</value></tag><tag><tag>pool</tag><value>{#POOLNAME}</value></tag></tags></item_prototype><item_prototype><uuid>4e49ce8a11084dd287f89b076cc70535</uuid><name>Ceph: [{#POOLNAME}] Max available</name><type>DEPENDENT</type><key>ceph.pool[&quot;{#POOLNAME}&quot;,max_avail]</key><delay>0</delay><history>7d</history><units>B</units><description>The maximum available space in the given pool.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.pools[&quot;{#POOLNAME}&quot;].max_avail</parameter></parameters></step></preprocessing><master_item><key>ceph.df.details[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>pools</value></tag><tag><tag>crushrule</tag><value>{#CRUSHRULE}</value></tag><tag><tag>pool</tag><value>{#POOLNAME}</value></tag></tags></item_prototype><item_prototype><uuid>5c7bd85f9d944215acaced87b0eb216f</uuid><name>Ceph: [{#POOLNAME}] Pool objects</name><type>DEPENDENT</type><key>ceph.pool[&quot;{#POOLNAME}&quot;,objects]</key><delay>0</delay><history>7d</history><description>The number of objects in the pool.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.pools[&quot;{#POOLNAME}&quot;].objects</parameter></parameters></step></preprocessing><master_item><key>ceph.df.details[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>pools</value></tag><tag><tag>crushrule</tag><value>{#CRUSHRULE}</value></tag><tag><tag>pool</tag><value>{#POOLNAME}</value></tag></tags></item_prototype><item_prototype><uuid>eda166ae6c4c46cf8c01c2b928f07ec5</uuid><name>Ceph: [{#POOLNAME}] Pool Percent Used</name><type>DEPENDENT</type><key>ceph.pool[&quot;{#POOLNAME}&quot;,percent_used]</key><delay>0</delay><history>7d</history><units>%</units><description>The percentage of the storage used per pool.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.pools[&quot;{#POOLNAME}&quot;].percent_used</parameter></parameters></step></preprocessing><master_item><key>ceph.df.details[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>pools</value></tag><tag><tag>crushrule</tag><value>{#CRUSHRULE}</value></tag><tag><tag>pool</tag><value>{#POOLNAME}</value></tag></tags></item_prototype><item_prototype><uuid>5311f1a539284c5483458e1820496be3</uuid><name>Ceph: [{#POOLNAME}] Pool Read bandwidth</name><type>DEPENDENT</type><key>ceph.pool[&quot;{#POOLNAME}&quot;,rd_bytes.rate]</key><delay>0</delay><history>7d</history><value_type>FLOAT</value_type><units>Bps</units><description>The read rate per pool (bytes per second).</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.pools[&quot;{#POOLNAME}&quot;].rd_bytes</parameter></parameters></step><step><type>CHANGE_PER_SECOND</type><parameters><parameter/></parameters></step></preprocessing><master_item><key>ceph.df.details[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>pools</value></tag><tag><tag>crushrule</tag><value>{#CRUSHRULE}</value></tag><tag><tag>pool</tag><value>{#POOLNAME}</value></tag></tags></item_prototype><item_prototype><uuid>76871b86d66d4307a83e813a8d9fc1b0</uuid><name>Ceph: [{#POOLNAME}] Pool Read operations</name><type>DEPENDENT</type><key>ceph.pool[&quot;{#POOLNAME}&quot;,rd_ops.rate]</key><delay>0</delay><history>7d</history><value_type>FLOAT</value_type><units>ops</units><description>The read rate per pool (operations per second).</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.pools[&quot;{#POOLNAME}&quot;].rd_ops</parameter></parameters></step><step><type>CHANGE_PER_SECOND</type><parameters><parameter/></parameters></step></preprocessing><master_item><key>ceph.df.details[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>pools</value></tag><tag><tag>crushrule</tag><value>{#CRUSHRULE}</value></tag><tag><tag>pool</tag><value>{#POOLNAME}</value></tag></tags></item_prototype><item_prototype><uuid>4c053bbaaf6946bcaf5288cc154d6fdd</uuid><name>Ceph: [{#POOLNAME}] Pool RAW Used</name><type>DEPENDENT</type><key>ceph.pool[&quot;{#POOLNAME}&quot;,stored_raw]</key><delay>0</delay><history>7d</history><units>B</units><description>Bytes used in pool including the copies made.</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.pools[&quot;{#POOLNAME}&quot;].stored_raw</parameter></parameters></step></preprocessing><master_item><key>ceph.df.details[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>pools</value></tag><tag><tag>crushrule</tag><value>{#CRUSHRULE}</value></tag><tag><tag>pool</tag><value>{#POOLNAME}</value></tag></tags></item_prototype><item_prototype><uuid>955353da182243e29d326b3b2807286a</uuid><name>Ceph: [{#POOLNAME}] Pool Write bandwidth</name><type>DEPENDENT</type><key>ceph.pool[&quot;{#POOLNAME}&quot;,wr_bytes.rate]</key><delay>0</delay><history>7d</history><value_type>FLOAT</value_type><units>Bps</units><description>The write rate per pool (bytes per second).</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.pools[&quot;{#POOLNAME}&quot;].wr_bytes</parameter></parameters></step><step><type>CHANGE_PER_SECOND</type><parameters><parameter/></parameters></step></preprocessing><master_item><key>ceph.df.details[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>pools</value></tag><tag><tag>crushrule</tag><value>{#CRUSHRULE}</value></tag><tag><tag>pool</tag><value>{#POOLNAME}</value></tag></tags></item_prototype><item_prototype><uuid>acb3081d772444dab060a055fb3f4304</uuid><name>Ceph: [{#POOLNAME}] Pool Write operations</name><type>DEPENDENT</type><key>ceph.pool[&quot;{#POOLNAME}&quot;,wr_ops.rate]</key><delay>0</delay><history>7d</history><value_type>FLOAT</value_type><units>ops</units><description>The write rate per pool (operations per second).</description><preprocessing><step><type>JSONPATH</type><parameters><parameter>$.pools[&quot;{#POOLNAME}&quot;].wr_ops</parameter></parameters></step><step><type>CHANGE_PER_SECOND</type><parameters><parameter/></parameters></step></preprocessing><master_item><key>ceph.df.details[&quot;{$CEPH.CONNSTRING}&quot;,&quot;{$CEPH.USER}&quot;,&quot;{$CEPH.API.KEY}&quot;]</key></master_item><tags><tag><tag>component</tag><value>pools</value></tag><tag><tag>crushrule</tag><value>{#CRUSHRULE}</value></tag><tag><tag>pool</tag><value>{#POOLNAME}</value></tag></tags></item_prototype></item_prototypes><graph_prototypes><graph_prototype><uuid>1a469f2c99214b1ba7fe3a7520e43439</uuid><name>Ceph: [{#POOLNAME}] Pool bandwidth</name><graph_items><graph_item><color>1A7C11</color><item><host>Ceph by Zabbix agent 2</host><key>ceph.pool[&quot;{#POOLNAME}&quot;,rd_bytes.rate]</key></item></graph_item><graph_item><sortorder>1</sortorder><color>2774A4</color><item><host>Ceph by Zabbix agent 2</host><key>ceph.pool[&quot;{#POOLNAME}&quot;,wr_bytes.rate]</key></item></graph_item></graph_items></graph_prototype><graph_prototype><uuid>7870932ea335481db1c23224dfb33f60</uuid><name>Ceph: [{#POOLNAME}] Pool I/O</name><graph_items><graph_item><color>1A7C11</color><item><host>Ceph by Zabbix agent 2</host><key>ceph.pool[&quot;{#POOLNAME}&quot;,rd_ops.rate]</key></item></graph_item><graph_item><sortorder>1</sortorder><color>2774A4</color><item><host>Ceph by Zabbix agent 2</host><key>ceph.pool[&quot;{#POOLNAME}&quot;,wr_ops.rate]</key></item></graph_item></graph_items></graph_prototype><graph_prototype><uuid>3da48042fdaa4c01825c3eea7ab5af6b</uuid><name>Ceph: [{#POOLNAME}] Pool Usage</name><graph_items><graph_item><color>1A7C11</color><item><host>Ceph by Zabbix agent 2</host><key>ceph.pool[&quot;{#POOLNAME}&quot;,bytes_used]</key></item></graph_item><graph_item><sortorder>1</sortorder><color>2774A4</color><item><host>Ceph by Zabbix agent 2</host><key>ceph.pool[&quot;{#POOLNAME}&quot;,max_avail]</key></item></graph_item><graph_item><sortorder>2</sortorder><color>F63100</color><item><host>Ceph by Zabbix agent 2</host><key>ceph.pool[&quot;{#POOLNAME}&quot;,stored_raw]</key></item></graph_item></graph_items></graph_prototype></graph_prototypes></discovery_rule></discovery_rules><tags><tag><tag>class</tag><value>application</value></tag><tag><tag>target</tag><value>ceph</value></tag></tags><macros><macro><macro>{$CEPH.API.KEY}</macro><value>zabbix_pass</value></macro><macro><macro>{$CEPH.CONNSTRING}</macro><value>https://localhost:8003</value></macro><macro><macro>{$CEPH.USER}</macro><value>zabbix</value></macro></macros><valuemaps><valuemap><uuid>2a4b2a8c55ba48b2a815e4123c9ea7fa</uuid><name>Ceph cluster status</name><mappings><mapping><value>0</value><newvalue>HEALTH_OK</newvalue></mapping><mapping><value>1</value><newvalue>HEALTH_WARN</newvalue></mapping><mapping><value>2</value><newvalue>HEALTH_ERR</newvalue></mapping></mappings></valuemap><valuemap><uuid>22fe6d6c74454775994f07fc05d7bafd</uuid><name>Service state</name><mappings><mapping><value>0</value><newvalue>Down</newvalue></mapping><mapping><value>1</value><newvalue>Up</newvalue></mapping></mappings></valuemap></valuemaps></template></templates><graphs><graph><uuid>fac43ab599344f1da374bd091f6b618b</uuid><name>Ceph: Cluster bandwidth</name><graph_items><graph_item><color>1A7C11</color><item><host>Ceph by Zabbix agent 2</host><key>ceph.rd_bytes.rate</key></item></graph_item><graph_item><sortorder>1</sortorder><color>2774A4</color><item><host>Ceph by Zabbix agent 2</host><key>ceph.wr_bytes.rate</key></item></graph_item></graph_items></graph><graph><uuid>4191a30a9a7c4e5aa48d96238ca8f20c</uuid><name>Ceph: Cluster I/O</name><graph_items><graph_item><color>1A7C11</color><item><host>Ceph by Zabbix agent 2</host><key>ceph.wr_ops.rate</key></item></graph_item><graph_item><sortorder>1</sortorder><color>2774A4</color><item><host>Ceph by Zabbix agent 2</host><key>ceph.rd_ops.rate</key></item></graph_item></graph_items></graph><graph><uuid>515e2c5239f94ee7a52ecdb834079e06</uuid><name>Ceph: Free space</name><type>STACKED</type><graph_items><graph_item><drawtype>FILLED_REGION</drawtype><color>1A7C11</color><item><host>Ceph by Zabbix agent 2</host><key>ceph.total_used_bytes</key></item></graph_item><graph_item><sortorder>1</sortorder><drawtype>FILLED_REGION</drawtype><color>2774A4</color><item><host>Ceph by Zabbix agent 2</host><key>ceph.total_avail_bytes</key></item></graph_item></graph_items></graph><graph><uuid>8714a8cf50bd43c2b54e410a439d320b</uuid><name>Ceph: Overall OSD latency</name><graph_items><graph_item><drawtype>BOLD_LINE</drawtype><color>1A7C11</color><item><host>Ceph by Zabbix agent 2</host><key>ceph.osd_latency_commit.avg</key></item></graph_item><graph_item><sortorder>1</sortorder><color>2774A4</color><item><host>Ceph by Zabbix agent 2</host><key>ceph.osd_latency_commit.max</key></item></graph_item><graph_item><sortorder>2</sortorder><color>F63100</color><item><host>Ceph by Zabbix agent 2</host><key>ceph.osd_latency_commit.min</key></item></graph_item><graph_item><sortorder>3</sortorder><drawtype>BOLD_LINE</drawtype><color>A54F10</color><item><host>Ceph by Zabbix agent 2</host><key>ceph.osd_latency_apply.avg</key></item></graph_item><graph_item><sortorder>4</sortorder><color>FC6EA3</color><item><host>Ceph by Zabbix agent 2</host><key>ceph.osd_latency_apply.max</key></item></graph_item><graph_item><sortorder>5</sortorder><color>6C59DC</color><item><host>Ceph by Zabbix agent 2</host><key>ceph.osd_latency_apply.min</key></item></graph_item></graph_items></graph><graph><uuid>716d959b255a47779b9aaf376be8ba03</uuid><name>Ceph: Overall OSD utilization</name><graph_items><graph_item><drawtype>BOLD_LINE</drawtype><color>1A7C11</color><item><host>Ceph by Zabbix agent 2</host><key>ceph.osd_fill.avg</key></item></graph_item><graph_item><sortorder>1</sortorder><color>2774A4</color><item><host>Ceph by Zabbix agent 2</host><key>ceph.osd_fill.max</key></item></graph_item><graph_item><sortorder>2</sortorder><color>F63100</color><item><host>Ceph by Zabbix agent 2</host><key>ceph.osd_fill.min</key></item></graph_item></graph_items></graph></graphs></zabbix_export>
